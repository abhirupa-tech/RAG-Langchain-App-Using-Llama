# RAG-Langchain-App-Using-Llama
Custom Trained LLM application with Llama, and grounding via RAG

Retrieval Augmented Generation (RAG) is a technique used to enhance the knowledge of large language models (LLMs) by incorporating additional, often private or real-time, data. While LLMs can reason about a wide range of topics, their knowledge is restricted to publicly available data up to a specific point in time when they were trained. However, if you aim to create AI applications capable of reasoning about private data or information introduced after a modelâ€™s training, you must augment the modelâ€™s knowledge with the specific details it requires. The process of integrating relevant information into the model prompt is referred to as Retrieval Augmented Generation (RAG). This approach allows LLMs to generate more contextually accurate and up-to-date responses. ðŸ˜Š
